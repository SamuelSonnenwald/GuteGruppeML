{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 5: Classification\n",
    "\n",
    "### 5.1. Parameter optimization\n",
    "In Exercise 4.2 we have used the German credit data set from the UCI data set library (http://archive.ics.uci.edu/ml/index.html), which describes the customers of a bank with respect to whether they should get a bank credit or not.\n",
    "\n",
    "#### 5.1.1.\t(recap) Go back to the results of exercise 4.2.4. Re-run the classifiers with their default parameter settings.\n",
    "- Used the 10-fold validation approach.\n",
    "- Balanced the training set multiplying the “bad customer” examples. \n",
    "- Evaluated the results, setting up your cost matrix to ((0,100)(1,0)) – that is, you assumed you will lose 1 Unit if you refuse a credit to a good customer, but that you lose 100 Units if you give a bad customer a credit.\n",
    "\n",
    "Rerun your process to get the performance results. What were the default parameters of the Decision Tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Desktop/ML Group 2/credit-g.arff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m arff\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m----> 5\u001b[0m credit_arff_data, credit_arff_meta \u001b[38;5;241m=\u001b[39m arff\u001b[38;5;241m.\u001b[39mloadarff(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDesktop/ML Group 2/credit-g.arff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m credit_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(credit_arff_data)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# select all columns of type object\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Desktop/ML Group 2/credit-g.arff'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "credit_arff_data, credit_arff_meta = arff.loadarff(open('credit-g.arff', 'r'))\n",
    "credit_data = pd.DataFrame(credit_arff_data)\n",
    "\n",
    "# select all columns of type object\n",
    "columns_with_binary_strings = credit_data.select_dtypes('object').columns.values\n",
    "\n",
    "# decode the values of these columns using utf-8\n",
    "credit_data[columns_with_binary_strings] = credit_data[columns_with_binary_strings].apply(lambda x: x.str.decode(\"utf-8\"))\n",
    "credit_target = credit_data['class']\n",
    "credit_data = credit_data.drop(columns='class')\n",
    "\n",
    "label = LabelEncoder()\n",
    "credit_target = label.fit_transform(credit_target)\n",
    "label_names=['bad','good']\n",
    "label_order=label.transform(label_names)\n",
    "\n",
    "credit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we set up a pipeline and evaluate it using cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "numeric_features = ['duration', 'credit_amount', 'installment_commitment', 'residence_since', 'age', 'existing_credits', 'num_dependents']\n",
    "categorical_features = ['credit_history', 'purpose', 'personal_status', 'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker']\n",
    "ordinal_features = [ 'checking_status', 'savings_status', 'employment']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('ord', OrdinalEncoder(categories=[\n",
    "            [ 'no checking', '<0', '0<=X<200', '>=200' ],\n",
    "            [ 'no known savings', '<100', '100<=X<500', '500<=X<1000', '>=1000' ],\n",
    "            [ 'unemployed', '<1', '1<=X<4', '4<=X<7', '>=7' ]\n",
    "        ]), ordinal_features)])\n",
    "\n",
    "pipeline = Pipeline([ \n",
    "    ('preprocessing', preprocessor), \n",
    "    ('balancing', RandomOverSampler()),\n",
    "    ('estimator', DecisionTreeClassifier()) ])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "prediction = cross_val_predict(pipeline, credit_data, credit_target, cv=cv)\n",
    "\n",
    "def cost_function(y_true, y_pred): \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=label_order)\n",
    "    return cm[0][1] * 100 + cm[1][0] * 1\n",
    "\n",
    "cm = confusion_matrix(credit_target, prediction, labels=label_order)\n",
    "cost = cost_function(credit_target, prediction)\n",
    "acc = accuracy_score(credit_target, prediction)\n",
    "\n",
    "print(\"Decision Tree with accuracy of {} and cost {}\".format(acc, cost))\n",
    "plot_confusion_matrix(cm, classes=label_names, title='Decision Tree Classifier')\n",
    "plt.show()\n",
    "print(classification_report(credit_target, prediction, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit the pipeline to the dataset and plot the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "pipeline.fit(credit_data, credit_target)\n",
    "\n",
    "estimator = pipeline.named_steps['estimator']\n",
    "pre = pipeline.named_steps['preprocessing']\n",
    "feature_names = numeric_features + list(pre.named_transformers_['cat'].get_feature_names_out(categorical_features)) + ordinal_features\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(estimator,\n",
    "               feature_names=feature_names,\n",
    "                class_names=label_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Default Parameters for decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 5.1.2.\tNow try to find a more optimal configuration for the Decision Tree. What is the best parameter setting and what is the cross-validated performance of this appraoch?\n",
    "\n",
    "Use the GridSearchCV from scikit learn. Try the following parameters of the Decision Tree:\n",
    "- criterion: ['gini', 'entropy']\n",
    "- 'max_depth': [2, 3, 4, 5, None]\n",
    "- 'min_samples_split' :[2,3,4,5]\n",
    "\n",
    "What is the best configuration for the data set and the classification approach? \n",
    "\n",
    "Note: The grid search can take some time. You can use the ```n_jobs=-1``` parameter setting for the ```cross_val_predict()``` function to enable parallel processing (all CPU cores will be used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the parameter grid\n",
    "parameters = {\n",
    "    'estimator__criterion':['gini', 'entropy'], \n",
    "    'estimator__max_depth':[ 2, 3, 4, 5, None],\n",
    "    'estimator__min_samples_split' :[2,3,4,5]\n",
    "}\n",
    "\n",
    "# define the folds for the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# create a scorer for the grid search\n",
    "cost_score = make_scorer(cost_function, greater_is_better=False)\n",
    "\n",
    "# create the grid search estimator\n",
    "grid_search_estimator = GridSearchCV(pipeline, parameters, scoring=cost_score, cv=stratified_10_fold_cv)\n",
    "\n",
    "# cross-validate\n",
    "prediction = cross_val_predict(grid_search_estimator, credit_data, credit_target, cv=cv, n_jobs=-1)\n",
    "\n",
    "# calculate costs\n",
    "cm = confusion_matrix(credit_target, prediction, labels=label_order)\n",
    "cost = cost_function(credit_target, prediction)\n",
    "acc = accuracy_score(credit_target, prediction)\n",
    "\n",
    "print(\"Optimised Decision Tree with accuracy of {} and cost {}\".format(acc, cost))\n",
    "plot_confusion_matrix(cm, classes=label_names, title='Decision Tree Classifier')\n",
    "plt.show()\n",
    "print(classification_report(credit_target, prediction, target_names=label_names))\n",
    "\n",
    "# fit the grid search (= determine the optimal parameters)\n",
    "grid_search_estimator.fit(credit_data, credit_target)\n",
    "print(\"Optimised Parameters: {}\".format(grid_search_estimator.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 5.1.4.\tHow does the optimal decision tree differ from the one you have learned in 4.2.4?\n",
    "Plot the optimised tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid_search_estimator.best_estimator_.named_steps['estimator']\n",
    "pre = grid_search_estimator.best_estimator_.named_steps['preprocessing']\n",
    "feature_names = numeric_features + list(pre.named_transformers_['cat'].get_feature_names_out(categorical_features)) + ordinal_features\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(estimator,\n",
    "               feature_names=feature_names,\n",
    "                class_names=label_names)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
